{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import concatenate, Dense, Flatten, Reshape, Input, Lambda, BatchNormalization, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, LeakyReLU, Conv2DTranspose,InputLayer, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('X_false.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = data.shape[0]\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "length = BUFFER_SIZE // BATCH_SIZE * BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype('float32') / 255.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(data).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 10\n",
    "\n",
    "def dropout_and_batch(x):\n",
    "    return Dropout(0.1)(BatchNormalization()(x))\n",
    "\n",
    "input_img = Input((32, 32, 3))\n",
    "x = Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation='relu')(input_img)\n",
    "x = dropout_and_batch(x)\n",
    "x = Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation='relu')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = dropout_and_batch(x)\n",
    "\n",
    "z_mean = Dense(hidden_dim)(x)\n",
    "z_log_var = Dense(hidden_dim)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noiser(args):\n",
    "    global z_mean, z_log_var\n",
    "    z_mean, z_log_var = args\n",
    "    N = K.random_normal(shape=(BATCH_SIZE, hidden_dim), mean=0., stddev=1.0)\n",
    "    return K.exp(z_log_var / 2) * N + z_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = Lambda(noiser, output_shape=(hidden_dim,))([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dec = Input((hidden_dim))\n",
    "d = Dense(units=8*8*32, activation='relu')(input_dec)\n",
    "d = dropout_and_batch(d)\n",
    "d = Reshape(target_shape=(8, 8, 32))(d)\n",
    "\n",
    "d = Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same', activation='relu')(d)\n",
    "d = dropout_and_batch(d)\n",
    "d = Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same', activation='relu')(d)\n",
    "d = dropout_and_batch(d)\n",
    "decoded = Conv2DTranspose(filters=3, kernel_size=3, strides=1, padding='same', activation='relu')(d)\n",
    "\n",
    "encoder = keras.Model(input_img, h, name='encoder')\n",
    "decoder = keras.Model(input_dec, decoded, name='decoder')\n",
    "generator = keras.Model(input_img, decoder(encoder(input_img)), name=\"generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = tf.keras.Sequential()\n",
    "discriminator.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[32, 32, 3]))\n",
    "discriminator.add(LeakyReLU())\n",
    "discriminator.add(Dropout(0.1))\n",
    "\n",
    "discriminator.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "discriminator.add(LeakyReLU())\n",
    "discriminator.add(Dropout(0.1))\n",
    "\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "    kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return (loss + kl_loss*0.1)\n",
    "\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = load_model('decoder')\n",
    "encoder.load_weights('encoder.h5')\n",
    "discriminator = load_model('discrim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(images, training=True)\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        \n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_img():\n",
    "    n = 2\n",
    "    total = 2*n+1\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    num = 1\n",
    "    for i in range(-n, n+1):\n",
    "          for j in range(-n, n+1):\n",
    "            ax = plt.subplot(total, total, num)\n",
    "            num += 1\n",
    "            img = decoder.predict(np.expand_dims([0.5*-1/n, 0.5*-1/n, 0.5*-1/n, 0.5*-1/n, 0.5*-1/n, 0.5*-1/n, 0.5*i/n, 0.5*i/n, 0.5*j/n, 0.5*j/n], axis=0))\n",
    "            plt.imshow(img.squeeze(), cmap='gray')\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    history = []\n",
    "    MAX_PRINT_LABEL = 10\n",
    "    th = BUFFER_SIZE // (BATCH_SIZE*MAX_PRINT_LABEL)\n",
    "    n_epoch = 1\n",
    "    for epoch in range(epochs):\n",
    "        print(f'{n_epoch}/{EPOCHS}: ', end='')\n",
    "\n",
    "        start = time.time()\n",
    "        n = 0\n",
    "        print('**')\n",
    "        gen_loss_epoch = 0\n",
    "        for image_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(image_batch)\n",
    "            gen_loss_epoch += K.mean(gen_loss)\n",
    "            if( n % th == 0): \n",
    "                print('=', end='')\n",
    "                n += 1\n",
    "\n",
    "        history += [gen_loss_epoch/n]\n",
    "        print(': '+str(history[-1]))\n",
    "        print ('Время эпохи {} в {} секундах'.format(epoch + 1, time.time()-start))\n",
    "        if (epoch + 1) % 25 == 0:\n",
    "            discriminator.save('discrim')\n",
    "            decoder.save('decoder')\n",
    "            encoder.save('encoder.h5')\n",
    "        n_epoch += 1\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/100: **\n",
      "=: tf.Tensor(1906.2515, shape=(), dtype=float32)\n",
      "Время эпохи 1 в 63.44171690940857 секундах\n",
      "2/100: **\n",
      "=: tf.Tensor(1211.7516, shape=(), dtype=float32)\n",
      "Время эпохи 2 в 79.38197159767151 секундах\n",
      "3/100: **\n",
      "=: tf.Tensor(692.2803, shape=(), dtype=float32)\n",
      "Время эпохи 3 в 76.23341703414917 секундах\n",
      "4/100: **\n",
      "=: tf.Tensor(667.57074, shape=(), dtype=float32)\n",
      "Время эпохи 4 в 79.5133786201477 секундах\n",
      "5/100: **\n",
      "=: tf.Tensor(594.8886, shape=(), dtype=float32)\n",
      "Время эпохи 5 в 69.13490319252014 секундах\n",
      "6/100: **\n",
      "=: tf.Tensor(594.30444, shape=(), dtype=float32)\n",
      "Время эпохи 6 в 75.35840106010437 секундах\n",
      "7/100: **\n",
      "=: tf.Tensor(634.6529, shape=(), dtype=float32)\n",
      "Время эпохи 7 в 50.66230344772339 секундах\n",
      "8/100: **\n",
      "=: tf.Tensor(641.5509, shape=(), dtype=float32)\n",
      "Время эпохи 8 в 55.312886238098145 секундах\n",
      "9/100: **\n",
      "=: tf.Tensor(657.0021, shape=(), dtype=float32)\n",
      "Время эпохи 9 в 43.06359386444092 секундах\n",
      "10/100: **\n",
      "=: tf.Tensor(644.8521, shape=(), dtype=float32)\n",
      "Время эпохи 10 в 45.155415773391724 секундах\n",
      "11/100: **\n",
      "=: tf.Tensor(558.0684, shape=(), dtype=float32)\n",
      "Время эпохи 11 в 43.26497220993042 секундах\n",
      "12/100: **\n",
      "=: tf.Tensor(546.96747, shape=(), dtype=float32)\n",
      "Время эпохи 12 в 44.303646087646484 секундах\n",
      "13/100: **\n",
      "=: tf.Tensor(567.214, shape=(), dtype=float32)\n",
      "Время эпохи 13 в 42.28102254867554 секундах\n",
      "14/100: **\n",
      "=: tf.Tensor(548.6974, shape=(), dtype=float32)\n",
      "Время эпохи 14 в 37.63464093208313 секундах\n",
      "15/100: **\n",
      "=: tf.Tensor(526.58075, shape=(), dtype=float32)\n",
      "Время эпохи 15 в 36.10253190994263 секундах\n",
      "16/100: **\n",
      "=: tf.Tensor(535.8105, shape=(), dtype=float32)\n",
      "Время эпохи 16 в 35.665895223617554 секундах\n",
      "17/100: **\n",
      "=: tf.Tensor(550.4474, shape=(), dtype=float32)\n",
      "Время эпохи 17 в 34.703877687454224 секундах\n",
      "18/100: **\n",
      "=: tf.Tensor(555.508, shape=(), dtype=float32)\n",
      "Время эпохи 18 в 34.9988431930542 секундах\n",
      "19/100: **\n",
      "=: tf.Tensor(540.38434, shape=(), dtype=float32)\n",
      "Время эпохи 19 в 53.0338819026947 секундах\n",
      "20/100: **\n",
      "=: tf.Tensor(545.9089, shape=(), dtype=float32)\n",
      "Время эпохи 20 в 35.451820850372314 секундах\n",
      "21/100: **\n",
      "=: tf.Tensor(546.4104, shape=(), dtype=float32)\n",
      "Время эпохи 21 в 49.66478633880615 секундах\n",
      "22/100: **\n",
      "=: tf.Tensor(545.0969, shape=(), dtype=float32)\n",
      "Время эпохи 22 в 35.58632516860962 секундах\n",
      "23/100: **\n",
      "=: tf.Tensor(509.98648, shape=(), dtype=float32)\n",
      "Время эпохи 23 в 35.93330407142639 секундах\n",
      "24/100: **\n",
      "=: tf.Tensor(503.29404, shape=(), dtype=float32)\n",
      "Время эпохи 24 в 37.013638496398926 секундах\n",
      "25/100: **\n",
      "=: tf.Tensor(518.85175, shape=(), dtype=float32)\n",
      "Время эпохи 25 в 38.43102169036865 секундах\n",
      "INFO:tensorflow:Assets written to: discrim\\assets\n",
      "INFO:tensorflow:Assets written to: decoder\\assets\n",
      "26/100: **\n",
      "=: tf.Tensor(520.8126, shape=(), dtype=float32)\n",
      "Время эпохи 26 в 38.094529151916504 секундах\n",
      "27/100: **\n",
      "=: tf.Tensor(550.6911, shape=(), dtype=float32)\n",
      "Время эпохи 27 в 34.88296461105347 секундах\n",
      "28/100: **\n",
      "=: tf.Tensor(550.33966, shape=(), dtype=float32)\n",
      "Время эпохи 28 в 36.72091197967529 секундах\n",
      "29/100: **\n",
      "=: tf.Tensor(535.6337, shape=(), dtype=float32)\n",
      "Время эпохи 29 в 36.83232760429382 секундах\n",
      "30/100: **\n",
      "=: tf.Tensor(544.11554, shape=(), dtype=float32)\n",
      "Время эпохи 30 в 35.946733236312866 секундах\n",
      "31/100: **\n",
      "=: tf.Tensor(549.42267, shape=(), dtype=float32)\n",
      "Время эпохи 31 в 35.73085021972656 секундах\n",
      "32/100: **\n",
      "=: tf.Tensor(555.74384, shape=(), dtype=float32)\n",
      "Время эпохи 32 в 37.35654139518738 секундах\n",
      "33/100: **\n",
      "=: tf.Tensor(563.383, shape=(), dtype=float32)\n",
      "Время эпохи 33 в 36.64282011985779 секундах\n",
      "34/100: **\n",
      "=: tf.Tensor(573.5246, shape=(), dtype=float32)\n",
      "Время эпохи 34 в 34.98241424560547 секундах\n",
      "35/100: **\n",
      "=: tf.Tensor(575.88806, shape=(), dtype=float32)\n",
      "Время эпохи 35 в 41.69335889816284 секундах\n",
      "36/100: **\n",
      "=: tf.Tensor(584.538, shape=(), dtype=float32)\n",
      "Время эпохи 36 в 35.3651168346405 секундах\n",
      "37/100: **\n",
      "=: tf.Tensor(587.3729, shape=(), dtype=float32)\n",
      "Время эпохи 37 в 34.271286725997925 секундах\n",
      "38/100: **\n",
      "=: tf.Tensor(583.30316, shape=(), dtype=float32)\n",
      "Время эпохи 38 в 35.21218466758728 секундах\n",
      "39/100: **\n",
      "=: tf.Tensor(587.6894, shape=(), dtype=float32)\n",
      "Время эпохи 39 в 35.944997787475586 секундах\n",
      "40/100: **\n",
      "=: tf.Tensor(579.4272, shape=(), dtype=float32)\n",
      "Время эпохи 40 в 33.98026752471924 секундах\n",
      "41/100: **\n",
      "=: tf.Tensor(593.4951, shape=(), dtype=float32)\n",
      "Время эпохи 41 в 32.944310665130615 секундах\n",
      "42/100: **\n",
      "=: tf.Tensor(610.564, shape=(), dtype=float32)\n",
      "Время эпохи 42 в 32.53118872642517 секундах\n",
      "43/100: **\n",
      "=: tf.Tensor(587.8803, shape=(), dtype=float32)\n",
      "Время эпохи 43 в 33.87475109100342 секундах\n",
      "44/100: **\n",
      "=: tf.Tensor(602.0113, shape=(), dtype=float32)\n",
      "Время эпохи 44 в 34.70600128173828 секундах\n",
      "45/100: **\n",
      "=: tf.Tensor(609.6887, shape=(), dtype=float32)\n",
      "Время эпохи 45 в 34.0143096446991 секундах\n",
      "46/100: **\n",
      "=: tf.Tensor(617.4988, shape=(), dtype=float32)\n",
      "Время эпохи 46 в 33.845479011535645 секундах\n",
      "47/100: **\n",
      "=: tf.Tensor(610.91284, shape=(), dtype=float32)\n",
      "Время эпохи 47 в 34.25181174278259 секундах\n",
      "48/100: **\n",
      "=: tf.Tensor(621.66223, shape=(), dtype=float32)\n",
      "Время эпохи 48 в 32.159663677215576 секундах\n",
      "49/100: **\n",
      "=: tf.Tensor(623.48206, shape=(), dtype=float32)\n",
      "Время эпохи 49 в 39.42808246612549 секундах\n",
      "50/100: **\n",
      "=: tf.Tensor(626.05585, shape=(), dtype=float32)\n",
      "Время эпохи 50 в 45.225173234939575 секундах\n",
      "INFO:tensorflow:Assets written to: discrim\\assets\n",
      "INFO:tensorflow:Assets written to: decoder\\assets\n",
      "51/100: **\n",
      "=: tf.Tensor(628.40454, shape=(), dtype=float32)\n",
      "Время эпохи 51 в 36.76358509063721 секундах\n",
      "52/100: **\n",
      "=: tf.Tensor(636.51184, shape=(), dtype=float32)\n",
      "Время эпохи 52 в 35.837116718292236 секундах\n",
      "53/100: **\n",
      "=: tf.Tensor(632.61755, shape=(), dtype=float32)\n",
      "Время эпохи 53 в 37.354278802871704 секундах\n",
      "54/100: **\n",
      "=: tf.Tensor(630.01025, shape=(), dtype=float32)\n",
      "Время эпохи 54 в 37.16286492347717 секундах\n",
      "55/100: **\n",
      "=: tf.Tensor(641.09375, shape=(), dtype=float32)\n",
      "Время эпохи 55 в 33.566028118133545 секундах\n",
      "56/100: **\n",
      "=: tf.Tensor(644.178, shape=(), dtype=float32)\n",
      "Время эпохи 56 в 36.521230936050415 секундах\n",
      "57/100: **\n",
      "=: tf.Tensor(648.8326, shape=(), dtype=float32)\n",
      "Время эпохи 57 в 35.735870122909546 секундах\n",
      "58/100: **\n",
      "=: tf.Tensor(648.2949, shape=(), dtype=float32)\n",
      "Время эпохи 58 в 38.99905061721802 секундах\n",
      "59/100: **\n",
      "=: tf.Tensor(656.7611, shape=(), dtype=float32)\n",
      "Время эпохи 59 в 32.86511254310608 секундах\n",
      "60/100: **\n",
      "=: tf.Tensor(671.0968, shape=(), dtype=float32)\n",
      "Время эпохи 60 в 33.83714747428894 секундах\n",
      "61/100: **\n",
      "=: tf.Tensor(666.46436, shape=(), dtype=float32)\n",
      "Время эпохи 61 в 32.64817929267883 секундах\n",
      "62/100: **\n",
      "=: tf.Tensor(669.89764, shape=(), dtype=float32)\n",
      "Время эпохи 62 в 33.79380249977112 секундах\n",
      "63/100: **\n",
      "=: tf.Tensor(669.0551, shape=(), dtype=float32)\n",
      "Время эпохи 63 в 32.31298780441284 секундах\n",
      "64/100: **\n",
      "=: tf.Tensor(677.77496, shape=(), dtype=float32)\n",
      "Время эпохи 64 в 47.11003613471985 секундах\n",
      "65/100: **\n",
      "=: tf.Tensor(686.1047, shape=(), dtype=float32)\n",
      "Время эпохи 65 в 35.25332856178284 секундах\n",
      "66/100: **\n",
      "=: tf.Tensor(667.0726, shape=(), dtype=float32)\n",
      "Время эпохи 66 в 38.235172271728516 секундах\n",
      "67/100: **\n",
      "="
     ]
    }
   ],
   "source": [
    "history = train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h = encoder.predict(data, batch_size=BATCH_SIZE)\n",
    "#plt.scatter(h[:, 0], h[:, 1])\n",
    "\n",
    "#plt.plot(history)\n",
    "#plt.grid(True)\n",
    "\n",
    "# отображение результатов генерации\n",
    "n = 2\n",
    "total = 2*n+1\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "num = 1\n",
    "for i in range(-n, n+1):\n",
    "      for j in range(-n, n+1):\n",
    "        ax = plt.subplot(total, total, num)\n",
    "        num += 1\n",
    "        img = decoder.predict(np.expand_dims([0.5*-1/n, 0.5*-1/n, 0.5*-1/n, 0.5*-1/n, 0.5*-1/n, 0.5*-1/n, 0.5*i/n, 0.5*i/n, 0.5*j/n, 0.5*j/n], axis=0))\n",
    "        plt.imshow(img.squeeze(), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = decoder.predict(np.expand_dims([0.5*-2/n, 0.5*-2/n, 0.5*1/n, 0.5*-1/n, 0.5*-1/n, 0.5*1/n, 0.5*-1/n, 0.5*-1/n, 0.5*-1/n, 0.5*-2/n], axis=0))\n",
    "plt.imshow(img.squeeze(), cmap='gray')\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.save('discrim')\n",
    "decoder.save('decoder')\n",
    "encoder.save('encoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
